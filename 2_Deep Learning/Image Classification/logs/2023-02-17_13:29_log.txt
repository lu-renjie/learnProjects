2023-02-17 13:29:23,311: batch_size: 32
2023-02-17 13:29:23,312: learning_rate: 0.01
2023-02-17 13:29:23,312: epoch_num: 1
2023-02-17 13:29:25,557: step: 50, loss:  1.1702, accuracy: 0.7703
2023-02-17 13:29:26,711: step: 100, loss:  0.8238, accuracy: 0.8362
2023-02-17 13:29:27,855: step: 150, loss:  0.8632, accuracy: 0.8413
2023-02-17 13:29:29,012: step: 200, loss:  0.8788, accuracy: 0.8607
2023-02-17 13:29:30,191: step: 250, loss:  0.6111, accuracy: 0.8654
2023-02-17 13:29:31,351: step: 300, loss:  0.4385, accuracy: 0.8635
2023-02-17 13:29:32,493: step: 350, loss:  0.6642, accuracy: 0.8695
2023-02-17 13:29:33,631: step: 400, loss:  0.4887, accuracy: 0.8754
2023-02-17 13:29:34,888: step: 450, loss:  0.4091, accuracy: 0.8779
2023-02-17 13:29:36,112: step: 500, loss:  0.4248, accuracy: 0.8799
2023-02-17 13:29:37,332: step: 550, loss:  0.5158, accuracy: 0.8795
2023-02-17 13:29:38,534: step: 600, loss:  0.3382, accuracy: 0.8854
2023-02-17 13:29:39,745: step: 650, loss:  0.5013, accuracy: 0.8798
2023-02-17 13:29:41,001: step: 700, loss:  0.4618, accuracy: 0.8879
2023-02-17 13:29:42,278: step: 750, loss:  0.3571, accuracy: 0.8855
2023-02-17 13:29:43,484: step: 800, loss:  0.5722, accuracy: 0.8888
2023-02-17 13:29:44,699: step: 850, loss:  0.3571, accuracy: 0.8879
2023-02-17 13:29:45,895: step: 900, loss:  0.5138, accuracy: 0.8906
2023-02-17 13:29:47,117: step: 950, loss:  0.6389, accuracy: 0.8897
2023-02-17 13:29:48,339: step: 1000, loss:  0.1633, accuracy: 0.8920
2023-02-17 13:29:49,534: step: 1050, loss:  0.2848, accuracy: 0.8934
2023-02-17 13:29:50,762: step: 1100, loss:  0.7034, accuracy: 0.8923
2023-02-17 13:29:51,982: step: 1150, loss:  0.3771, accuracy: 0.8951
2023-02-17 13:29:53,186: step: 1200, loss:  0.4881, accuracy: 0.8937
2023-02-17 13:29:54,418: step: 1250, loss:  0.3926, accuracy: 0.8938
2023-02-17 13:29:55,637: step: 1300, loss:  0.4599, accuracy: 0.8953
2023-02-17 13:29:56,856: step: 1350, loss:  0.5850, accuracy: 0.8961
2023-02-17 13:29:58,056: step: 1400, loss:  0.5551, accuracy: 0.8949
2023-02-17 13:29:59,276: step: 1450, loss:  0.5629, accuracy: 0.8943
2023-02-17 13:30:00,526: step: 1500, loss:  0.3231, accuracy: 0.8952
2023-02-17 13:30:01,734: step: 1550, loss:  0.5537, accuracy: 0.8966
2023-02-17 13:30:02,947: step: 1600, loss:  0.3339, accuracy: 0.8970
2023-02-17 13:30:04,168: step: 1650, loss:  0.6180, accuracy: 0.8968
2023-02-17 13:30:05,387: step: 1700, loss:  0.2915, accuracy: 0.8963
2023-02-17 13:30:06,592: step: 1750, loss:  0.3002, accuracy: 0.8967
2023-02-17 13:30:07,799: step: 1800, loss:  0.2651, accuracy: 0.8967
2023-02-17 13:30:09,024: step: 1850, loss:  0.1828, accuracy: 0.8967
2023-02-17 13:30:09,307: epoch[1/1], lr:  0.0000e+00
2023-02-17 13:30:09,309: time consuming: 45.996893882751465
