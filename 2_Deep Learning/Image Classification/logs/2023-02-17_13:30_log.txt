2023-02-17 13:30:43,668: batch_size: 32
2023-02-17 13:30:43,668: learning_rate: 0.01
2023-02-17 13:30:43,668: epoch_num: 1
2023-02-17 13:30:46,290: step: 50, loss:  0.6361, accuracy: 0.7802
2023-02-17 13:30:47,585: step: 100, loss:  0.3129, accuracy: 0.8081
2023-02-17 13:30:48,836: step: 150, loss:  0.6156, accuracy: 0.8138
2023-02-17 13:30:50,112: step: 200, loss:  0.8645, accuracy: 0.8515
2023-02-17 13:30:51,361: step: 250, loss:  0.4157, accuracy: 0.8731
2023-02-17 13:30:52,598: step: 300, loss:  0.2264, accuracy: 0.8673
2023-02-17 13:30:53,845: step: 350, loss:  0.3411, accuracy: 0.8894
2023-02-17 13:30:55,081: step: 400, loss:  0.1551, accuracy: 0.8456
2023-02-17 13:30:56,317: step: 450, loss:  0.1876, accuracy: 0.8737
2023-02-17 13:30:57,601: step: 500, loss:  0.6898, accuracy: 0.8663
2023-02-17 13:30:58,863: step: 550, loss:  0.7635, accuracy: 0.8508
2023-02-17 13:31:00,158: step: 600, loss:  0.7514, accuracy: 0.8561
2023-02-17 13:31:01,422: step: 650, loss:  0.7616, accuracy: 0.8622
2023-02-17 13:31:02,667: step: 700, loss:  0.2410, accuracy: 0.8558
2023-02-17 13:31:03,899: step: 750, loss:  0.6788, accuracy: 0.8700
2023-02-17 13:31:05,144: step: 800, loss:  0.1360, accuracy: 0.9021
2023-02-17 13:31:06,422: step: 850, loss:  0.2004, accuracy: 0.8878
2023-02-17 13:31:07,665: step: 900, loss:  0.4309, accuracy: 0.8813
2023-02-17 13:31:08,904: step: 950, loss:  0.0901, accuracy: 0.8637
2023-02-17 13:31:10,161: step: 1000, loss:  0.5443, accuracy: 0.8989
2023-02-17 13:31:11,401: step: 1050, loss:  0.2933, accuracy: 0.8914
2023-02-17 13:31:12,650: step: 1100, loss:  0.7985, accuracy: 0.9001
2023-02-17 13:31:13,893: step: 1150, loss:  0.3407, accuracy: 0.8740
2023-02-17 13:31:15,164: step: 1200, loss:  0.4035, accuracy: 0.8952
2023-02-17 13:31:16,422: step: 1250, loss:  0.6826, accuracy: 0.9030
2023-02-17 13:31:17,693: step: 1300, loss:  0.1742, accuracy: 0.9014
2023-02-17 13:31:18,964: step: 1350, loss:  0.6100, accuracy: 0.9116
2023-02-17 13:31:20,225: step: 1400, loss:  0.2447, accuracy: 0.9086
2023-02-17 13:31:21,465: step: 1450, loss:  0.1495, accuracy: 0.9150
2023-02-17 13:31:22,696: step: 1500, loss:  0.1149, accuracy: 0.9061
2023-02-17 13:31:23,981: step: 1550, loss:  0.0631, accuracy: 0.9181
2023-02-17 13:31:25,248: step: 1600, loss:  0.1946, accuracy: 0.9167
2023-02-17 13:31:26,579: step: 1650, loss:  0.1847, accuracy: 0.9179
2023-02-17 13:31:27,854: step: 1700, loss:  0.1699, accuracy: 0.9193
2023-02-17 13:31:29,129: step: 1750, loss:  0.1914, accuracy: 0.9189
2023-02-17 13:31:30,402: step: 1800, loss:  0.2416, accuracy: 0.9191
2023-02-17 13:31:31,688: step: 1850, loss:  0.1220, accuracy: 0.9197
2023-02-17 13:31:31,993: epoch[1/1], lr:  0.0000e+00
2023-02-17 13:31:31,993: time consuming: 48.324647188186646
