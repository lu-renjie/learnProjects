2023-02-17 13:27:31,847: batch_size: 32
2023-02-17 13:27:31,848: learning_rate: 0.01
2023-02-17 13:27:31,848: epoch_num: 1
2023-02-17 13:27:34,078: step: 100, loss:  0.7888, accuracy: 0.8236
2023-02-17 13:27:35,343: step: 200, loss:  0.7230, accuracy: 0.8555
2023-02-17 13:27:36,595: step: 300, loss:  0.7142, accuracy: 0.8689
2023-02-17 13:27:37,821: step: 400, loss:  0.6158, accuracy: 0.8694
2023-02-17 13:27:39,059: step: 500, loss:  0.5291, accuracy: 0.8694
2023-02-17 13:27:40,291: step: 600, loss:  0.7626, accuracy: 0.8696
2023-02-17 13:27:41,527: step: 700, loss:  0.8309, accuracy: 0.8696
2023-02-17 13:27:42,739: step: 800, loss:  0.7515, accuracy: 0.8694
2023-02-17 13:27:43,943: step: 900, loss:  0.4326, accuracy: 0.8694
2023-02-17 13:27:45,171: step: 1000, loss:  0.5014, accuracy: 0.8694
2023-02-17 13:27:46,381: step: 1100, loss:  0.6534, accuracy: 0.8694
2023-02-17 13:27:47,609: step: 1200, loss:  0.4923, accuracy: 0.8694
2023-02-17 13:27:48,856: step: 1300, loss:  0.6187, accuracy: 0.8694
2023-02-17 13:27:50,069: step: 1400, loss:  0.7984, accuracy: 0.8694
2023-02-17 13:27:51,284: step: 1500, loss:  0.7016, accuracy: 0.8694
2023-02-17 13:27:52,488: step: 1600, loss:  0.8323, accuracy: 0.8694
2023-02-17 13:27:53,718: step: 1700, loss:  0.5013, accuracy: 0.8694
2023-02-17 13:27:54,923: step: 1800, loss:  0.5084, accuracy: 0.8694
2023-02-17 13:27:55,255: epoch[1/1], lr:  1.0000e-11
2023-02-17 13:27:55,256: time consuming: 23.407575130462646
